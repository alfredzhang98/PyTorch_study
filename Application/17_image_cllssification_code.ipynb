{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea67b79e",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "\n",
    "我们需要区分logo和其他的类别，因此我们将数据集划分为训练集、验证集和测试集，分别存放在不同的文件夹中：\n",
    "\n",
    "```python\n",
    "train_dir = './data/work1/train'\n",
    "train_logo_dir = './data/work1/train_logo'\n",
    "train_other_dir = './data/work1/train_other'\n",
    "val_dir = './data/work1/val'\n",
    "val_logo_dir = './data/work1/val_logo'\n",
    "val_other_dir = './data/work1/val_other'\n",
    "```\n",
    "\n",
    "\n",
    "训练模型的时候你应该侧重精确率还是召回率？\n",
    "在训练模型时，选择侧重精确率还是召回率取决于具体的应用场景和业务需求。\n",
    "- 如果假阳性（false positive）代价较高，例如在垃圾邮件过滤中，误将正常邮件标记为垃圾邮件会导致用户体验下降，那么应该侧重提高精确率。\n",
    "- 如果假阴性（false negative）代价较高，例如在疾病筛查中，漏掉患病个体可能会导致严重后果，那么应该侧重提高召回率。\n",
    "- 在某些情况下，可能需要在精确率和召回率之间找到一个平衡点，这时可以使用F1分数作为评估指标。\n",
    "\n",
    "对于logo识别任务，通常更关注召回率，因为漏掉一个logo可能会导致用户无法识别品牌，从而影响用户体验和品牌形象。因此，在训练模型时，可能会更侧重于提高召回率，以确保尽可能多的logo被正确识别出来。当然，具体的侧重点还需要根据实际应用场景进行调整。\n",
    "\n",
    "git clone https://github.com/syuu1987/geekTime-image-classification\n",
    "\n",
    "![image4.png](mdfiles/image4.png)\n",
    "\n",
    "作者比较了单独放大这三个维度中的任意一个维度效果如何。得出结论是放大网络深度或网络宽度或图像分辨率，均可提升模型精度，但是越放大，精度增加越缓慢，且计算复杂度 FLOPS 增加较快。\n",
    "\n",
    "因此，作者提出了混合维度放大法，该方法使用一个 ϕ（混合稀疏）来决定三个维度的放大倍率。\n",
    "\n",
    "深度 \n",
    "$depth：d=αϕ$\n",
    "\n",
    "宽度 \n",
    "$width：w=βϕ$\n",
    "\n",
    "分辨率 \n",
    "$resolution：r=γϕ$\n",
    "\n",
    "$$\n",
    "    s.t. α⋅β^2⋅γ^2≈2, α≥1, β≥1, γ≥1\n",
    "$$\n",
    "\n",
    "s.t. 是什么意思？\n",
    "s.t. 是 \"subject to\" 的缩写，意思是 \"在...条件下\" 或 \"受...约束\"。在数学优化问题中，s.t. 用于引入约束条件，表示在满足这些条件的前提下进行优化。\n",
    "\n",
    "固定 ϕ 为 1，也就是计算量为 2 倍时，使用网格搜索法找到 α、β、γ 的最优解，分别为 1.2、1.1、1.15。\n",
    "然后固定 α 为 1.2，β 为 1.1，γ 为 1.15，调整 ϕ 的值来放大网络。 得到B1 到 B7 共 8 个 EfficientNet 模型。\n",
    "\n",
    "上述操作的原因是？\n",
    "\n",
    "通过固定其他两个维度的放大倍率，调整混合稀疏 ϕ 的值，可以在保持计算量相对稳定的情况下，探索不同的网络结构组合，从而找到最优的模型配置。\n",
    "\n",
    "![image5.png](mdfiles/image5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783efb5",
   "metadata": {},
   "source": [
    "EfficientNet 利用一种复合的缩放手段，对网络的深度 depth、宽度 width 和分辨率 resolution 同时进行缩放（按照一定的缩放规律），来达到精度和运算复杂度 FLOPS 的权衡。\n",
    "\n",
    "但即使只探索这三个维度，搜索空间仍然很大，所以作者规定只在 B0（作者提出的 EfficientNet 的一个 Baseline）上进行放大。\n",
    "\n",
    "如何理解放大 深度，宽度，分辨率？\n",
    "- 深度 scaling depth：增加网络的层数，使得模型能够学习到更复杂的特征表示。\n",
    "- 宽度 scaling width：增加每一层的通道数，使得模型能够捕捉到更多的特征。\n",
    "- 分辨率 scaling resolution：增加输入图像的分辨率，使得模型能够获取更细粒度的图像信息。\n",
    "通过这种复合的缩放方法，EfficientNet 能够在保持较低计算复杂度的同时，显著提升模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72ca307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "# 这个可以快速方便数据读出处理\n",
    "\n",
    "def _norm_advprop(img):\n",
    "    # 为什么 * 2.0 - 1.0 ?\n",
    "    # 因为我们希望将输入图像的像素值范围从 [0, 1] 线性映射到 [-1, 1]\n",
    "    return img * 2.0 - 1.0\n",
    "\n",
    "def build_transform(dest_image_size):\n",
    "    # lambda 方式实现归一化\n",
    "    normalize = transforms.Lambda(_norm_advprop)\n",
    "\n",
    "    if not isinstance(dest_image_size, tuple):\n",
    "        dest_image_size = (dest_image_size, dest_image_size)\n",
    "    else:\n",
    "        dest_image_size = dest_image_size\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        # 先缩放再裁剪保证尺寸一致\n",
    "        transforms.RandomResizedCrop(dest_image_size),\n",
    "        # 随机水平翻转\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "    return transform\n",
    "\n",
    "def build_data_set(dest_image_size, data):\n",
    "    transform = build_transform(dest_image_size) \n",
    "    dataset=datasets.ImageFolder(data, transform=transform, target_transform=None) \n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b70b85",
   "metadata": {},
   "source": [
    "![image6.png](mdfiles/image6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a871e776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found train dir: data/work1/train. Classes: ['logo', 'others'] (count=2)\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "=> using pre-trained model 'efficientnet-b0'\n",
      "Epoch 0 | step 0 | loss 0.7223\n",
      "Epoch 0 | step 1 | loss 0.7417\n",
      "Epoch 1 | step 0 | loss 0.7709\n",
      "Epoch 1 | step 1 | loss 0.8034\n",
      "Epoch 2 | step 0 | loss 0.6751\n",
      "Epoch 2 | step 1 | loss 0.7021\n",
      "Epoch 3 | step 0 | loss 0.6279\n",
      "Epoch 3 | step 1 | loss 0.6618\n",
      "Epoch 4 | step 0 | loss 0.5962\n",
      "Epoch 4 | step 1 | loss 0.6511\n",
      "Epoch 5 | step 0 | loss 0.5748\n",
      "Epoch 5 | step 1 | loss 0.5387\n",
      "Epoch 6 | step 0 | loss 0.5416\n",
      "Epoch 6 | step 1 | loss 0.5221\n",
      "Epoch 7 | step 0 | loss 0.4599\n",
      "Epoch 7 | step 1 | loss 0.6675\n",
      "Epoch 8 | step 0 | loss 0.4153\n",
      "Epoch 8 | step 1 | loss 0.4239\n",
      "Epoch 9 | step 0 | loss 0.3326\n",
      "Epoch 9 | step 1 | loss 0.3877\n"
     ]
    }
   ],
   "source": [
    "from efficientnet import EfficientNet\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, args, device):\n",
    "    model.train()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # === 关键：把数据搬到同一设备 ===\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        # CE 需要 int64 的类别索引\n",
    "        target = target.to(device, non_blocking=True).long()\n",
    "\n",
    "        # forward\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        print(f'Epoch {epoch} | step {i} | loss {loss.item():.4f}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if args.pretrained:\n",
    "        # 使用预训练模型，在这里就进行微调了，num_classes 指定新的类别数量为 args.classes_num\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0',\n",
    "                                             num_classes=args.classes_num,\n",
    "                                             advprop=args.advprop)\n",
    "        print(f\"=> using pre-trained model '{args.arch}'\")\n",
    "    else:\n",
    "        print(f\"=> creating model '{args.arch}'\")\n",
    "        model = EfficientNet.from_name(args.arch, num_classes=args.classes_num)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # CrossEntropyLoss 包含了 Softmax 和 NLLLoss\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "\n",
    "    use_pin = torch.cuda.is_available()\n",
    "    \n",
    "    # args.train_data 指定训练数据集路径\n",
    "    train_dataset = build_data_set(args.image_size, args.train_data)\n",
    "    # use_pin 用于加速数据传输到 GPU\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=args.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=args.num_workers,\n",
    "                              pin_memory=use_pin)\n",
    "\n",
    "    \n",
    "    # 创建 checkpoint 目录\n",
    "    os.makedirs(args.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    # 开始训练\n",
    "    for epoch in range(args.epochs):\n",
    "        train(train_loader, model, criterion, optimizer, epoch, args, device)\n",
    "        if epoch % args.save_interval == 0:\n",
    "            torch.save(model.state_dict(),\n",
    "                       os.path.join(args.checkpoint_dir, f'checkpoint.pth.tar.epoch_{epoch}'))\n",
    "\n",
    "# Quick dataset check: detect class folders under ./data/work1/train and set detected_classes_num\n",
    "# This cell is safe to run in the notebook and will help set the default number of classes.\n",
    "import os\n",
    "from pathlib import Path\n",
    "train_path = Path('./data/work1/train')\n",
    "if train_path.exists():\n",
    "    # class_dirs is logo and other folders under train/, this way is to create the class_dirs automatically\n",
    "    class_dirs = sorted([p.name for p in train_path.iterdir() if p.is_dir()])\n",
    "    # 获取类别数量\n",
    "    detected_classes_num = len(class_dirs) if class_dirs else 0\n",
    "    print(f'Found train dir: {train_path}. Classes: {class_dirs} (count={detected_classes_num})')\n",
    "else:\n",
    "    detected_classes_num = 0\n",
    "    print(f'WARNING: Train dir {train_path} not found. Please prepare training data at ./data/work1/train')\n",
    "    raise FileNotFoundError(f'Train dir {train_path} not found.')\n",
    "\n",
    "# Use a Namespace with default values so the notebook can run without CLI args.\n",
    "# Edit these defaults directly in the notebook as needed.\n",
    "args = argparse.Namespace(\n",
    "    train_data='./data/work1/train',\n",
    "    image_size=224, # 输入图片的宽和高，B0 推荐 224\n",
    "    batch_size=10,  # each GPU batch size\n",
    "    num_workers=4,  # data loading workers\n",
    "    epochs=10,      # total training epochs\n",
    "    lr=0.001,       # learning rate\n",
    "    checkpoint_dir='./ckpts/', # checkpoint save path\n",
    "    save_interval=1,           # save checkpoint every N epochs\n",
    "    momentum=0.9,              # momentum 动量 目的是加快 SGD 优化器的收敛速度\n",
    "    weight_decay=1e-4,         # 权重衰减（L2 正则化）\n",
    "    arch='efficientnet-b0',    # 模型架构\n",
    "    pretrained=True,           # 是否使用预训练权重\n",
    "    advprop=False,             # 是否使用 advprop 预训练权重\n",
    "    classes_num=detected_classes_num if detected_classes_num > 0 else 2  # default to 2 if not detected\n",
    ")\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2b6948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val classes: ['logo', 'others']\n",
      "Val class_to_idx: {'logo': 0, 'others': 1}\n",
      "每个类别的样本数量: {'logo': 17, 'others': 11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1644670/3405174438.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(latest, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集: 样本 28 | Loss 0.4378 | Top-1 准确率 96.43% | 来自权重: checkpoint.pth.tar.epoch_9\n",
      "误分类样本数: 1\n",
      "./data/work1/val/others/11.jpeg | 真: others -> 预测: logo\n"
     ]
    }
   ],
   "source": [
    "# 给我使用val数据集进行验证\n",
    "\n",
    "# 使用 val 数据集进行验证（简洁版）\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from efficientnet import EfficientNet\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 设备\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 验证集 DataLoader\n",
    "use_pin = torch.cuda.is_available()\n",
    "# 定义一个数据集包装类，使 __getitem__ 返回 (img, label, path) 方便定位误分类样本\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super().__getitem__(index)\n",
    "        path = self.samples[index][0]\n",
    "        return img, target, path\n",
    "\n",
    "val_dataset = ImageFolderWithPaths('./data/work1/val', transform=build_transform(args.image_size))\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                          batch_size=args.batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=args.num_workers,\n",
    "                          pin_memory=use_pin)\n",
    "\n",
    "print('Val classes:', val_dataset.classes)\n",
    "print('Val class_to_idx:', val_dataset.class_to_idx)\n",
    "\n",
    "# how many pics in each class\n",
    "class_counts = {}\n",
    "for _, label in val_dataset.samples:\n",
    "    class_name = val_dataset.classes[label]\n",
    "    if class_name in class_counts:\n",
    "        class_counts[class_name] += 1\n",
    "    else:\n",
    "        class_counts[class_name] = 1\n",
    "\n",
    "print('每个类别的样本数量:', class_counts)\n",
    "\n",
    "# 构建模型并加载最新权重\n",
    "model = EfficientNet.from_name(args.arch, num_classes=args.classes_num)\n",
    "ckpt_dir = Path(args.checkpoint_dir)\n",
    "ckpts = sorted(ckpt_dir.glob('checkpoint.pth.tar.epoch_*'))\n",
    "if not ckpts:\n",
    "    raise FileNotFoundError(f'未找到权重文件，请先完成训练: {ckpt_dir}')\n",
    "latest = ckpts[-1]\n",
    "state = torch.load(latest, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 验证循环：计算Top-1准确率与平均Loss\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "total = 0\n",
    "correct = 0\n",
    "loss_sum = 0.0\n",
    "# 记录误分类样本 (path, true_name, pred_name)\n",
    "misclassified = []\n",
    "idx2class = {i: c for i, c in enumerate(val_dataset.classes)}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, target, paths in val_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True).long()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        loss_sum += loss.item() * images.size(0)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += (pred == target).sum().item()\n",
    "        # 收集误分类\n",
    "        for j in range(images.size(0)):\n",
    "            pi = int(pred[j].item())\n",
    "            ti = int(target[j].item())\n",
    "            if pi != ti:\n",
    "                misclassified.append((paths[j], idx2class[ti], idx2class[pi]))\n",
    "        total += target.size(0)\n",
    "\n",
    "avg_loss = loss_sum / max(total, 1)\n",
    "acc = correct / max(total, 1)\n",
    "print(f'验证集: 样本 {total} | Loss {avg_loss:.4f} | Top-1 准确率 {acc*100:.2f}% | 来自权重: {latest.name}')\n",
    "\n",
    "# 输出误分类样本名称（显示前 50 条，避免过长）\n",
    "print(f'误分类样本数: {len(misclassified)}')\n",
    "for p, tname, pname in misclassified[:50]:\n",
    "    print(f'{p} | 真: {tname} -> 预测: {pname}')\n",
    "if len(misclassified) > 50:\n",
    "    print(f'... 仅显示前 50 条，共 {len(misclassified)} 条')\n",
    "\n",
    "\n",
    "# 我引入的没有logo的分别放在了 val 的 logo 和 other 文件夹下\n",
    "# 这个被误判为logo\n",
    "# 这个模型真正学习到的东西是什么呢，需要仔细考虑一下"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
