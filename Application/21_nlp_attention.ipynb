{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55f631e5",
   "metadata": {},
   "source": [
    "## NLP中的注意力机制\n",
    "\n",
    "对于一个确定的概念或者表达，判断哪种表示结果是最有可能的\n",
    "\n",
    "可以使用概率统计的方法来建立一个语言模型，这种模型我们称之为统计语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380be2fe",
   "metadata": {},
   "source": [
    "### 统计语言模型\n",
    "\n",
    "最为经典的就是基于马尔可夫假设 n-gram 语言模型，它也是被广泛采用的模型之一。n-gram 模型通过考虑前 n 个词来预测下一个词，从而捕捉到一定的上下文信息。\n",
    "\n",
    "S=w1,w2,w3,…,wn，则生成该句子的概率为：p(S)=p(w1,w2,w3,w4,w5,…,wn) 无非是一个概率传递的过程，有一个非常本质的问题并没有被解决，那就是语料中数据必定存在稀疏的问题，公式中的很多部分是没有统计值的，那就成了 0 了，而且参数量真的实在是太大了。\n",
    "\n",
    "$$\n",
    "p(S)=p(w1)⋅p(w2|w1)⋅p(w3|w1,w2)⋅p(w4|w1,w2,w3)⋅…⋅p(wn|w1,w2,…,wn−1)\n",
    "$$\n",
    "\n",
    "\n",
    "对于文本中的一个词，它出现的概率，很大程度上是由这个单词前面的一个或者几个单词决定的，这就是马尔可夫假设\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ed6a2",
   "metadata": {},
   "source": [
    "简化的程度取决于你认为一个单词是由前面的几个单词所决定的，\n",
    "\n",
    "\n",
    "如果只由前面的一个单词决定, bi-gram 模型\n",
    "\n",
    "$$\n",
    "p(wn|wn-1)\n",
    "$$\n",
    "\n",
    "如果由前面的两个单词决定, tri-gram 模型\n",
    "\n",
    "$$\n",
    "p(wn|wn-2,wn-1)\n",
    "$$\n",
    "\n",
    "如果只跟自己本身有关，那就是 unigram 模型\n",
    "$$\n",
    "p(wn)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e68427",
   "metadata": {},
   "source": [
    "### 神经网络语言模型\n",
    "\n",
    "词向量表示语义之间的关系，神经网络语言模型通过将词映射到一个连续的向量空间中，捕捉词与词之间的语义关系，从而提高语言模型的性能。\n",
    "\n",
    "M 表示的是词语的数量，N 表示词语的维度\n",
    "\n",
    "随机初始化的，那么就意味着这个向量空间不能作为我们的语言模型使用。下面我们就要想办法让这个矩阵学到内容。\n",
    "\n",
    "神经网络语言模型也是通过 ngram 来进行语言建模\n",
    "\n",
    "ngram 长度为 n，那么我们就从词向量矩阵中找到对应的前 n-1 个词的向量，经过若干层神经网络（包括激活函数），将这 n-1 个词的向量映射到对应的条件概率分布空间中。最后，模型就可以通过参数更新的方式，学习词向量的映射关系参数，以及上下文单词出现的条件概率参数了。\n",
    "\n",
    "![image15.png](mdfiles/image15.png)\n",
    "\n",
    "使用 n-1 个词，预测第 n 个词\n",
    "类型的神经网络语言模型我们称之为前馈网络语言模型\n",
    "\n",
    "\n",
    "LSTM 的语言模型下一个说用于预测情感分类\n",
    "\n",
    "\n",
    "统计语言模型的本质是基于词与词共现频次的统计，而神经网络语言模型则是给每个词分别赋予了向量空间的位置作为表征，从而计算它们在高维连续空间中的依赖关系。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
