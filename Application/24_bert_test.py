# %%
import os
import torch
from transformers import BartTokenizer, BartForConditionalGeneration
import evaluate # ç”¨äºè®¡ç®— ROUGE åˆ†æ•°
import numpy as np

# --- 1. è·¯å¾„å’Œç¯å¢ƒé…ç½® (åŸºäºæ‚¨çš„æœ€ç»ˆç¡®è®¤) ---

# 1.1 è·¯å¾„è®¾ç½® (å‡è®¾æµ‹è¯•è„šæœ¬ä¸è®­ç»ƒè„šæœ¬åœ¨åŒä¸€ç›®å½•)
try:
    # å°è¯•è·å–å½“å‰æ–‡ä»¶è·¯å¾„
    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
except NameError:
    # å¦‚æœåœ¨äº¤äº’å¼ç¯å¢ƒ (å¦‚ Jupyter/IPython) è¿è¡Œ
    SCRIPT_DIR = os.getcwd() 
    print(f"Warning: Running in interactive mode. Assuming script directory is: {SCRIPT_DIR}")

# æ¨¡å‹åŠ è½½è·¯å¾„
CKPT_DIR = os.path.join(SCRIPT_DIR, "ckpts", "bart_cnn_summary")
MODEL_NAME = 'facebook/bart-large-cnn' 

# 1.2 å¼ºåˆ¶ç¯å¢ƒè®¾ç½®ï¼šè§£å†³ CUDA/NCCL é”™è¯¯
os.environ["NCCL_P2P_DISABLE"] = "1"
os.environ["NCCL_IB_DISABLE"] = "1"
# éš”ç¦» GPU 3ï¼Œç¡®ä¿ Trainer åªåœ¨å•ä¸ª GPU ä¸Šè¿è¡Œ (ç‰©ç† GPU 3 -> é€»è¾‘ cuda:0)
os.environ["CUDA_VISIBLE_DEVICES"] = "3" 
os.environ["NCCL_DEBUG"] = "INFO" 
torch.cuda.empty_cache()

# --- 2. æ¨¡å‹å’Œåˆ†è¯å™¨åˆå§‹åŒ– ---

# ç”±äºè®¾ç½®äº† CUDA_VISIBLE_DEVICES="3"ï¼Œç›®æ ‡è®¾å¤‡åº”ä¸º cuda:0
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Device set: {device}")
print(f"Loading model from: {CKPT_DIR} onto device: {device}")

try:
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    model = BartForConditionalGeneration.from_pretrained(CKPT_DIR).to(device)
    # åŠ è½½å¯¹åº”çš„åˆ†è¯å™¨
    tokenizer = BartTokenizer.from_pretrained(MODEL_NAME)
    print("Model and tokenizer loaded successfully.")
except Exception as e:
    print(f"\n é”™è¯¯ï¼šæ— æ³•åŠ è½½æ¨¡å‹æˆ–åˆ†è¯å™¨ã€‚è¯·æ£€æŸ¥è·¯å¾„ {CKPT_DIR} æ˜¯å¦å­˜åœ¨ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶ã€‚")
    print(f"è¯¦ç»†é”™è¯¯: {e}")
    # ç¡®ä¿åŠ è½½å¤±è´¥æ—¶ï¼Œè„šæœ¬ä¸ä¼šç»§ç»­å°è¯•è°ƒç”¨æ¨¡å‹
    model = None 
    tokenizer = None
    exit()

# --- 3. æ‘˜è¦ç”Ÿæˆå‡½æ•° (å·²ä¿®å¤ length_penalty é”™è¯¯) ---

def generate_summary(text):
    """ä½¿ç”¨åŠ è½½çš„æ¨¡å‹å’Œåˆ†è¯å™¨ç”Ÿæˆæ‘˜è¦ã€‚"""
    
    inputs = tokenizer(
        [text], 
        max_length=1024, 
        return_tensors='pt', 
        truncation=True
    ).to(device)
    
    # ä¿®å¤äº† length_penalty=None çš„é”™è¯¯ï¼Œè®¾ç½®ä¸º 0.6
    summary_ids = model.generate(
        inputs['input_ids'], 
        max_length=130,      
        min_length=30,       
        num_beams=4,         
        do_sample=False,     
        early_stopping=True,
        length_penalty=0.6 # <--- å…³é”®ä¿®å¤ç‚¹
    )
    
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary

# --- 4. è‡ªåŠ¨åŒ–æµ‹è¯•å’Œå¯¹æ¯”åˆ†æ ---

# å®šä¹‰æµ‹è¯•æ–‡ç« å’Œå‚è€ƒæ‘˜è¦
TEST_ARTICLE = """ A new study published in the journal Nature Astronomy suggests that there may be a vast, hidden ocean beneath the icy crust of Pluto's largest moon, Charon. Researchers from the Southwest Research Institute analyzed data collected by NASA's New Horizons mission during its 2015 flyby. They found deep fissures and surface fractures that indicate Charon's surface expanded at some point in its history. This expansion is consistent with a subsurface ocean that froze, causing the moon's outer layers to stretch and crack. If water were present, it would offer another potential location for astrobiological interest in the Kuiper Belt, far beyond Neptune. The current model suggests the ocean may be up to 100 kilometers thick and is likely frozen solid now, but liquid water may have persisted for billions of years due to radioactive decay heating the interior."""

REFERENCE_SUMMARY = """Scientists analyzed New Horizons data from Charon and found deep fissures and fractures, suggesting the moon's surface expanded due to a vast, subsurface ocean. The ocean may have been liquid for billions of years, heated by radioactive decay, and is now likely frozen solid, providing another potential location for astrobiological study."""

print("\n==================================================")
print("             ğŸš€ è‡ªåŠ¨åŒ–æµ‹è¯•å’Œ ROUGE åˆ†æ ğŸš€")
print("==================================================")

# 1. ç”Ÿæˆæ¨¡å‹æ‘˜è¦
try:
    model_summary = generate_summary(TEST_ARTICLE)
except Exception as e:
    print(f"\nâŒ è‡´å‘½é”™è¯¯ï¼šæ¨¡å‹ç”Ÿæˆæ‘˜è¦å¤±è´¥ã€‚è¯¦ç»†é”™è¯¯: {e}")
    model_summary = "æ‘˜è¦ç”Ÿæˆå¤±è´¥"


print("\n--- åŸå§‹æ–‡ç«  ---")
print(TEST_ARTICLE[:200] + "...")

print("\n--- æ ‡å‡†å‚è€ƒæ‘˜è¦ ---")
print(REFERENCE_SUMMARY)

print("\n--- æ‚¨çš„æ¨¡å‹æ‘˜è¦ ---")
print(model_summary)


# 2. è®¡ç®— ROUGE åˆ†æ•° (ä»…å½“æ‘˜è¦æˆåŠŸç”Ÿæˆæ—¶)
if model_summary != "æ‘˜è¦ç”Ÿæˆå¤±è´¥":
    try:
        rouge = evaluate.load("rouge")
        results = rouge.compute(predictions=[model_summary], references=[REFERENCE_SUMMARY])

        print("\n--- ROUGE å¯¹æ¯”åˆ†æç»“æœ (F1 Score) ---")

        # æ ¼å¼åŒ–è¾“å‡º ROUGE ç»“æœ
        for key, value in results.items():
            if isinstance(value, dict) and 'fmeasure' in value:
                f1_score = value['fmeasure'] * 100 # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            elif isinstance(value, float):
                f1_score = value * 100
            else:
                continue
                
            print(f"| {key.ljust(9)} | {f1_score:.2f}%")

        print("--------------------------------------------------")
        print("ROUGE F1 Score è¶Šé«˜ï¼Œè¡¨æ˜æ‚¨çš„æ‘˜è¦ä¸å‚è€ƒæ‘˜è¦è¶Šç›¸ä¼¼ã€‚")
    except Exception as e:
        print(f"\nROUGE è¯„ä¼°è®¡ç®—å¤±è´¥ï¼šè¯·ç¡®ä¿æ‚¨å·²å®‰è£… 'evaluate' å’Œ 'rouge-score'ã€‚è¯¦ç»†é”™è¯¯: {e}")
    
print("==================================================")

# --- 5. äº¤äº’å¼å¾ªç¯ (æ¥ç»­) ---

print("\n--- äº¤äº’å¼æ‘˜è¦ç”Ÿæˆæ¨¡å¼ ---")
print("æ‚¨å¯ä»¥ç»§ç»­è¾“å…¥è‡ªå®šä¹‰æ–‡ç« è¿›è¡Œæµ‹è¯•ï¼Œæˆ–è¾“å…¥ 'exit' é€€å‡ºç¨‹åºã€‚\n")

while True:
    try:
        article_text = input("æ–‡ç« å†…å®¹ >>> ")
        
        if article_text.lower() in ['exit', 'quit']:
            print("é€€å‡ºæ‘˜è¦ç¨‹åºã€‚")
            break
        
        if not article_text.strip():
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡ç« å†…å®¹ã€‚\n")
            continue

        print("\nâ³ æ­£åœ¨ç”Ÿæˆæ‘˜è¦...")
        summary_result = generate_summary(article_text)
        
        print("\n--- æ‘˜è¦ç»“æœ ---")
        print(summary_result)
        print("------------------\n")
        
    except KeyboardInterrupt:
        print("\næ•è·åˆ°ä¸­æ–­ä¿¡å·ï¼Œé€€å‡ºç¨‹åºã€‚")
        break
    except Exception as e:
        print(f"\nå¤„ç†é”™è¯¯: {e}")
        print("è¯·é‡è¯•æˆ–æ£€æŸ¥è¾“å…¥ã€‚\n")