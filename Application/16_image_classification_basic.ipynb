{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df9eb932",
   "metadata": {},
   "source": [
    "输入层 → [卷积层 → 激活 → 池化]×N → 全连接层 → 输出层\n",
    "         ↓                     ↓\n",
    "      BatchNorm / Dropout    Softmax / Sigmoid\n",
    "           ↓                     ↓\n",
    "        损失函数 → 反向传播 → 优化器更新参数\n",
    "\n",
    "池化在所有神经网络都有吗？\n",
    "不是，池化层主要用于卷积神经网络（CNN）中，以减少特征图的尺寸和计算量，同时保留重要的空间信息。在某些网络架构中，可能会省略池化层，或者使用其他技术（如步幅卷积）来实现类似的效果。\n",
    "除了cnn，还有哪些网络会用到池化层？\n",
    "\n",
    "除了卷积神经网络（CNN），池化层还可以在以下类型的网络中使用：\n",
    "1. **循环神经网络（RNN）**：在某些变体中，池化层可以用于处理序列数据，以提取重要的时间步特征。\n",
    "2. **图神经网络（GNN）**：在处理图结构数据时，池化操作可以用于聚合节点特征。\n",
    "3. **自注意力网络**：在某些自注意力机制中，池化可以用于减少特征维度。\n",
    "\n",
    "## 神经网络的完整结构组成（系统视角）\n",
    "\n",
    "| 层级 | 组成部分 | 说明 |\n",
    "|------|-----------|------|\n",
    "| **1️⃣ 基本单元层** | **神经元 (Neuron)** | 模拟生物神经元的计算单元，接收输入、加权求和、加偏置、通过激活函数输出。 |\n",
    "|  | **激活函数 (Activation Function)** | 引入非线性，使网络能拟合复杂函数（如 Sigmoid、ReLU、Tanh、Softmax）。 |\n",
    "| **2️⃣ 网络结构层** | **全连接层 (Fully Connected Layer / Dense)** | 每个神经元与前一层所有输出相连，用于高维特征融合。 |\n",
    "|  | **卷积层 (Convolutional Layer)** | 通过卷积核提取局部特征，常用于图像任务。 |\n",
    "|  | **池化层 (Pooling Layer)** | 降维、保留主要特征（如 Max Pooling、Average Pooling）。 |\n",
    "|  | **归一化层 (Normalization Layer)** | 稳定训练、加速收敛（如 BatchNorm、LayerNorm）。 |\n",
    "|  | **Dropout 层 (Regularization)** | 随机丢弃部分神经元，防止过拟合。 |\n",
    "| **3️⃣ 模型输出层** | **输出层 (Output Layer)** | 将网络输出映射为预测结果，如分类概率或回归值。 |\n",
    "| **4️⃣ 学习机制层** | **损失函数 (Loss Function)** | 衡量预测与真实标签之间的差异（如 MSE、CrossEntropy）。 |\n",
    "|  | **优化器 (Optimizer)** | 更新网络参数以最小化损失（如 SGD、Adam、RMSProp）。 |\n",
    "| **5️⃣ 训练与传播机制** | **前向传播 (Forward Propagation)** | 输入 → 加权求和 → 激活 → 输出。 |\n",
    "|  | **反向传播 (Backpropagation)** | 计算梯度并通过链式法则更新权重。 |\n",
    "|  | **梯度下降 (Gradient Descent)** | 基于梯度方向调整参数，最小化损失。 |\n",
    "| **6️⃣ 数据与正则化机制** | **输入层 (Input Layer)** | 接收原始数据。 |\n",
    "|  | **数据预处理 / 增广 (Preprocessing / Augmentation)** | 提高泛化能力。 |\n",
    "|  | **正则化 (Regularization)** | 包括 L1/L2 权重衰减、Early Stopping 等。 |\n",
    "| **7️⃣ 训练控制与性能模块** | **学习率调度 (Scheduler)** | 动态调整学习率。 |\n",
    "|  | **评估指标 (Metrics)** | 如 Accuracy、Precision、Recall、IoU 等。 |\n",
    "|  | **模型保存 / 检查点 (Checkpoint)** | 保存最优模型参数。 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec1cc7d",
   "metadata": {},
   "source": [
    "## 感知机\n",
    "\n",
    "感知机（Perceptron）是机器学习中的一种基本的线性分类模型，由Frank Rosenblatt在1958年提出。它是神经网络的最简单形式，主要用于二分类任务。\n",
    "\n",
    "感知机的基本思想是通过对输入特征进行加权求和，然后通过一个激活函数（通常是阶跃函数）来决定输出类别。具体来说，感知机的工作流程如下：\n",
    "1. **输入特征**  \n",
    "   感知机接收一个输入向量  \n",
    "   $$\n",
    "   \\mathbf{x} = [x_1, x_2, \\ldots, x_n]\n",
    "   $$\n",
    "   其中每个 \\(x_i\\) 是输入的一个特征。\n",
    "\n",
    "2. **权重与偏置**  \n",
    "   每个输入特征对应一个权重  \n",
    "   $$\n",
    "   \\mathbf{w} = [w_1, w_2, \\ldots, w_n]\n",
    "   $$\n",
    "   同时设有一个偏置项 \\(b\\)。\n",
    "\n",
    "3. **加权求和**  \n",
    "   计算输入特征的加权和：  \n",
    "   $$\n",
    "   z = \\mathbf{w} \\cdot \\mathbf{x} + b = \\sum_{i=1}^{n} w_i x_i + b\n",
    "   $$\n",
    "\n",
    "4. **激活函数**  \n",
    "   将 \\(z\\) 输入到激活函数（通常为阶跃函数）：  \n",
    "   $$\n",
    "   f(z) =\n",
    "   \\begin{cases}\n",
    "   1, & \\text{若 } z \\ge 0 \\\\\n",
    "   0, & \\text{若 } z < 0\n",
    "   \\end{cases}\n",
    "   $$\n",
    "\n",
    "5. **输出类别**  \n",
    "   根据激活函数的结果，感知机将输入样本分类为 **类别 1** 或 **类别 0**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c9b572",
   "metadata": {},
   "source": [
    "## 神经元\n",
    "\n",
    "神经元（Neuron）是神经网络中的基本计算单元，模拟生物神经元的工作方式。每个神经元接收多个输入信号，通过加权求和和激活函数处理后，输出一个信号。神经元的工作流程与感知机类似，但通常使用更复杂的激活函数，如ReLU、Sigmoid或Tanh。\n",
    "$$ \n",
    " y_i = (w_{i1}x_1 + w_{i2}x_2 + ... + w_{in}x_n + b_i) * \\delta\n",
    "$$\n",
    "$\\delta$为激活函数。\n",
    "\n",
    "1. **输入信号**  \n",
    "   神经元接收一个输入向量  \n",
    "   $$\n",
    "   \\mathbf{x} = [x_1, x_2, \\ldots, x_n]\n",
    "   $$\n",
    "    其中每个 \\(x_i\\) 是输入的一个信号。\n",
    "2. **权重与偏置**  \n",
    "   每个输入信号对应一个权重  \n",
    "   $$\n",
    "   \\mathbf{w} = [w_1, w_2, \\ldots, w_n]\n",
    "   $$\n",
    "   同时设有一个偏置项 \\(b\\)。   \n",
    "3. **加权求和**  \n",
    "   计算输入信号的加权和：  \n",
    "   $$\n",
    "   z = \\mathbf{w} \\cdot \\mathbf{x} + b = \\sum_{i=1}^{n} w_i x_i + b\n",
    "   $$\n",
    "4. **激活函数**\n",
    "    将 \\(z\\) 输入到激活函数（如ReLU、Sigmoid等）：  \n",
    "    - ReLU（Rectified Linear Unit）:  \n",
    "    $$\n",
    "    f(z) = \\max(0, z)\n",
    "    $$\n",
    "    - Sigmoid:  \n",
    "    $$\n",
    "    f(z) = \\frac{1}{1 + e^{-z}}\n",
    "    $$\n",
    "    - Tanh:  \n",
    "    $$\n",
    "    f(z) = \\tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}\n",
    "    $$\n",
    "    - softmax（用于多分类任务）:  \n",
    "    $$\n",
    "    f(z_i) = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}\n",
    "    $$\n",
    "\n",
    "5. **输出信号**  \n",
    "   根据激活函数的结果，神经元输出一个信号，传递给下一层神经元或作为最终输出。\n",
    "\n",
    "\n",
    "表格对比这几个激活函数的用途和使用情况\n",
    "| 激活函数 | 公式 | 用途 | 特点 |\n",
    "| --- | --- | --- | --- |\n",
    "| ReLU | \\(f(z) = \\max(0, z)\\) | 常用于隐藏层 | 计算简单，收敛快，但可能导致“神经元死亡”问题 |\n",
    "| Sigmoid | \\(f(z) = \\frac{1}{1 + e^{-z}}\\) | 常用于二分类输出层 | 输出范围在0到1之间，适合概率输出，但易饱和 |\n",
    "| Tanh | \\(f(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}\\) | 常用于隐藏层 | 输出范围在-1到1之间，中心化效果好，但易饱和 |\n",
    "| softmax | \\(f(z_i) = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}\\) | 常用于多分类输出层 | 输出为概率分布，适合多分类任务 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019871dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.4559,  0.3468])\n",
      "tensor([0.1415, 0.8585])\n",
      "tensor([-0.8968,  0.3335])\n",
      "tensor([0.0000, 0.3468])\n",
      "tensor([0.1891, 0.5858])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Softmax 经过 Softmax 之后，原始的输出 y 是不是转换成一组概率，并且概率的和为 1 呢。原始 y 中最大的 y 具有最大的概率。\n",
    "y = torch.randn(2)\n",
    "print(y)\n",
    "\n",
    "m = nn.Softmax(dim=0)\n",
    "output = m(y)\n",
    "print(output)\n",
    "\n",
    "# Tanh Tanh 会把输入映射到 -1 到 1 之间。\n",
    "tanh = nn.Tanh()\n",
    "output = tanh(y)\n",
    "print(output)\n",
    "\n",
    "# ReLU ReLU 会把小于 0 的值都变成 0，大于 0 的值保持不变。\n",
    "relu = nn.ReLU()\n",
    "output = relu(y)\n",
    "print(output)\n",
    "\n",
    "# Sigmoid Sigmoid 会把输入映射到 0 到 1 之间。 为什么合不是1呢？\n",
    "# 因为 Sigmoid 的输出是一个个独立的值，并不是一组概率分布。\n",
    "sigmoid = nn.Sigmoid()\n",
    "output = sigmoid(y)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c7a26",
   "metadata": {},
   "source": [
    "全局平均池化（下面的图）用“求平均”代替了“粗暴地拍扁”，使得网络不再依赖于固定的输入尺寸，变得更加灵活和高效。 这也是为什么现代很多优秀的网络结构（如 ResNet, Inception）都采用了这种设计\n",
    "\n",
    "![image1.png](mdfiles/image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05425b04",
   "metadata": {},
   "source": [
    "## 卷积神经网络\n",
    "\n",
    "基于ImageNet比赛中表现优异的卷积神经网络架构：\n",
    "\n",
    "### VGG\n",
    "证明了随着模型深度的增加，模型效果也会越来越好。\n",
    "使用较小的 3x3 的卷积，代替了 AlexNet 中的 11x11、7x7 以及 5x5 的大卷积核。\n",
    "\n",
    "\n",
    "### GoogLeNet\n",
    "GoogLeNet 的核心是 Inception 模块，通过并行使用不同大小的卷积核（1x1、3x3、5x5）和池化层，捕捉多尺度特征。\n",
    "\n",
    "作者为了降低网络的计算成本，将上述的 Inception 模块做了一步改进，在 3x3、5x5 之前与 pooling 之后添加了 1x1 卷积用来降维\n",
    "\n",
    "为什么1x1卷积可以降维？\n",
    "1x1卷积通过在每个像素位置上应用一个线性变换，将输入通道数映射到较少的输出通道数，从而实现降维。\n",
    "\n",
    "![image2.png](mdfiles/image2.png)\n",
    "\n",
    "https://blog.csdn.net/sscc_learning/article/details/79863922\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8a2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接3×3卷积参数量: 0.295 M\n",
      "1×1降维后卷积参数量: 0.090 M\n"
     ]
    }
   ],
   "source": [
    "# 1x1卷积的作用1： 减少数据量\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 输入特征图假设为 256 个通道，尺寸 28×28\n",
    "x = torch.randn(1, 256, 28, 28)\n",
    "\n",
    "# 方法1：直接 3×3 卷积到 128通道\n",
    "conv_direct = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "params_direct = sum(p.numel() for p in conv_direct.parameters())\n",
    "\n",
    "# 方法2：先 1×1 降维到 64通道，再 3×3 到128通道\n",
    "conv_reduce = nn.Sequential(\n",
    "    nn.Conv2d(256, 64, kernel_size=1),     # 降维\n",
    "    nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    ")\n",
    "params_reduce = sum(p.numel() for p in conv_reduce.parameters())\n",
    "\n",
    "print(f\"直接3×3卷积参数量: {params_direct/1e6:.3f} M\")\n",
    "print(f\"1×1降维后卷积参数量: {params_reduce/1e6:.3f} M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c1ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.5361]],\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         [[-0.2692]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2869]],\n",
      "\n",
      "         [[ 0.4891]],\n",
      "\n",
      "         [[-0.2847]]]], requires_grad=True)\n",
      "输出形状: torch.Size([1, 2, 4, 4])\n",
      "输出第1通道（融合R和G）:\n",
      " tensor([[ 6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13.],\n",
      "        [14., 15., 16., 17.],\n",
      "        [18., 19., 20., 21.]], grad_fn=<SelectBackward0>)\n",
      "输出第2通道（融合G和B）:\n",
      " tensor([[10., 11., 10., 11.],\n",
      "        [11., 10., 11., 10.],\n",
      "        [10., 11., 10., 11.],\n",
      "        [11., 10., 11., 10.]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 1x1卷积的作用2： 数据融合 / 主动升维和降维\n",
    "# 降维常用于 减少计算量、压缩模型大小，提升推理速度，\n",
    "# 升维常用于 增加通道数、恢复特征维度、增强表达能力，\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 模拟 1 张 RGB 图像，大小 4×4\n",
    "x = torch.tensor([[[[1., 2., 3., 4.],\n",
    "                    [5., 6., 7., 8.],\n",
    "                    [9.,10.,11.,12.],\n",
    "                    [13.,14.,15.,16.]],\n",
    "                   [[10.,10.,10.,10.],\n",
    "                    [10.,10.,10.,10.],\n",
    "                    [10.,10.,10.,10.],\n",
    "                    [10.,10.,10.,10.]],\n",
    "                   [[0.,1.,0.,1.],\n",
    "                    [1.,0.,1.,0.],\n",
    "                    [0.,1.,0.,1.],\n",
    "                    [1.,0.,1.,0.]]]])  # shape (1,3,4,4)\n",
    "\n",
    "# 1×1卷积: 输入3通道 → 输出2通道\n",
    "conv = nn.Conv2d(3, 2, kernel_size=1, bias=False)\n",
    "\n",
    "# 手动设置权重来直观展示融合\n",
    "print(conv.weight) # 随机的初始权重\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor([\n",
    "        [[[1]], [[0.5]], [[0]]],     # 通道融合方式1\n",
    "        [[[0]], [[1]], [[1]]]        # 通道融合方式2\n",
    "    ])\n",
    "\n",
    "y = conv(x)\n",
    "print(\"输出形状:\", y.shape)\n",
    "print(\"输出第1通道（融合R和G）:\\n\", y[0,0])\n",
    "print(\"输出第2通道（融合G和B）:\\n\", y[0,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e640f88",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "ResNet 通过引入残差连接（skip connections），解决了深层网络训练中的梯度消失问题，使得网络可以更深，同时保持良好的性能。\n",
    "\n",
    "如何引入的残差连接？\n",
    "在 ResNet 中，残差连接通过将输入直接添加到输出的方式引入。具体来说，假设某一层的输入为 \\(x\\)，经过一系列卷积和激活操作后得到输出 \\(F(x)\\)，ResNet 会将输入 \\(x\\) 与输出 \\(F(x)\\) 相加，形成最终的输出：\n",
    "$$\n",
    "y = F(x) + x\n",
    "$$\n",
    "\n",
    "18 层、34 层、50 层、101 层与 152 层的 ResNet。101 层的与 152 层的残差神经网络效果最好，但是受硬件设备以及推断时间的限制，50 层的残差神经网络在实际项目中更为常用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e6733",
   "metadata": {},
   "source": [
    "网络退化问题\n",
    "\n",
    "随着网络深度的不断增加，网络的整体性能也会提升。如果只是单纯的增加网络，就会引起以下两个问题：第一，模型容易过拟合；第二，产生梯度消失、梯度爆炸的问题。\n",
    "\n",
    "上两个问题被规避之后，简单的堆叠卷积层，依然不能获得很好的效果。\n",
    "\n",
    "作者做了这样的一个实验。通过搭建一个普通的 20 层卷积神经网络与一个 56 层的卷积神经网络，在 CIFAR-10 数据集上进行了验证。无论训练集误差还是测试集误差，56 层的网络均高于 20 层的网络\n",
    "\n",
    "假设 20 层是一个最优的网络，通过加深到 56 层之后，理论上后面的 36 层是可以通过学习到一个恒等映射的，也就是说理论上不会学习到一个比 26 层还差的网络。\n",
    "\n",
    "所以，作者猜测网络不能很容易地学习到恒等映射 (恒等映射就是 f(x)=x)\n",
    "\n",
    "通过简单堆叠卷积层似乎很难学会到恒等映射\n",
    "\n",
    "深度残差学习的框架\n",
    "\n",
    "![image3.png](mdfiles/image3.png)\n",
    "\n",
    "shortcut connection 的机制来完成的。在残差神经网络中 shortcut connection 就是恒等变换，就是上图中带有 x identity 的那条曲线，包含 shortcut connection 的几层网络我们称之为残差块。\n",
    "最后作者发现，通过残差块，就可以训练出更深、更加优秀的卷积神经网络了。为什么呢？\n",
    "\n",
    "因为残差块通过引入 shortcut connection，使得网络更容易学习到恒等映射，从而缓解了深层网络中的梯度消失问题。\n",
    "\n",
    "恒等映射的好处是什么呢？\n",
    "\n",
    "恒等映射的好处在于它使得网络更容易优化，尤其是在深层网络中。通过学习恒等映射，网络可以更轻松地传递梯度，从而缓解梯度消失问题。这意味着即使在非常深的网络中，前面的层也能获得有效的梯度信息，从而进行有效的更新。\n",
    "\n",
    "具体来说，假设某一层的输入为 \\(x\\)，经过一系列卷积和激活操作后得到输出 \\(F(x)\\)，ResNet 会将输入 \\(x\\) 与输出 \\(F(x)\\) 相加，形成最终的输出：\n",
    "$$\n",
    "y = F(x) + x\n",
    "$$\n",
    "这样的结构被称为“残差块”（Residual Block），它允许网络学习到输入与输出之间的残差（Residual），从而更容易地学习到恒等映射。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434e09a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
