{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d94a7b",
   "metadata": {},
   "source": [
    "# 数据类\n",
    "\n",
    "dataset and dataloader 是 PyTorch 中用于处理和加载数据的两个重要组件。它们在深度学习模型的训练和评估过程中起着关键作用。\n",
    "## Dataset\n",
    "`Dataset` 是一个抽象类，表示数据集。它定义了如何访问数据的接口。要创建自定义数据集，通常需要继承 `torch.utils.data.Dataset` 并实现以下两个方法：\n",
    "- `__init__(self, ...)`: 初始化数据集，加载数据并进行必要的预处理。\n",
    "- `__len__(self)`: 返回数据集的大小（样本数量）。\n",
    "- `__getitem__(self, idx)`: 根据索引 `idx` 返回数据集中的一个样本（通常是一个输入-标签对）。\n",
    "\n",
    "## DataLoader\n",
    "`DataLoader` 是一个用于加载数据的迭代器。它可以将 `Dataset` 包装起来，提供批量加载数据、打乱数据顺序以及并行加载数据的功能。使用 `DataLoader` 可以方便地在训练过程中按批次获取数据。创建 `DataLoader` 时，通常需要指定以下参数：\n",
    "- `dataset`: 传入一个 `Dataset` 对象。\n",
    "- `batch_size`: 每个批次加载的样本数量。\n",
    "- `shuffle`: 是否在每个 epoch 开始时打乱数据。\n",
    "- `num_workers`: 用于数据加载的子进程数量。\n",
    "- `collate_fn`: 用于将样本列表合并为一个批次的函数。\n",
    "- `drop_last`: 如果数据集大小不能被批次大小整除，是否丢弃最后一个不完整的批次。\n",
    "- `pin_memory`: 如果设置为 `True`，数据加载器会将张量复制到 CUDA 固定内存中，以加快 GPU 训练速度。\n",
    "- `timeout`: 设置数据加载的超时时间（秒）。\n",
    "通过结合使用 `Dataset` 和 `DataLoader`，可以高效地管理和加载数据，从而简化深度学习模型的训练和评估过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d71591b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小: 10\n",
      "样本 0: 数据 = tensor([ 0.6902,  1.1503, -1.1787]), 标签 = 0\n",
      "样本 1: 数据 = tensor([ 1.0030,  1.0919, -0.8640]), 标签 = 1\n",
      "样本 2: 数据 = tensor([ 0.2210, -0.9095, -0.0576]), 标签 = 1\n",
      "样本 3: 数据 = tensor([0.0184, 1.4856, 0.0274]), 标签 = 0\n",
      "样本 4: 数据 = tensor([-0.5267, -1.0533, -0.3102]), 标签 = 0\n",
      "样本 5: 数据 = tensor([-1.0900,  0.1568, -0.4889]), 标签 = 0\n",
      "样本 6: 数据 = tensor([-1.0130, -0.5799, -0.5116]), 标签 = 1\n",
      "样本 7: 数据 = tensor([-1.1589, -0.4115,  0.9700]), 标签 = 0\n",
      "样本 8: 数据 = tensor([-2.1477,  0.5268,  0.3675]), 标签 = 1\n",
      "样本 9: 数据 = tensor([ 0.5944, -0.1394,  2.4881]), 标签 = 0\n"
     ]
    }
   ],
   "source": [
    "# Dataset 类\n",
    "# PyTorch 中的 Dataset 类是一个抽象类，它可以用来表示数据集\n",
    "# 用户可以通过继承 Dataset 类并实现其中的 __len__ 和 __getitem__ 方法来创建自定义的数据集\n",
    "# __init__()：构造函数，可自定义数据读取方法以及进行数据预处理；\n",
    "# __len__()：返回数据集的大小，即数据集中样本的数量；\n",
    "# __getitem__()：根据索引 idx 返回数据集中的一个样本，通常包括输入数据和对应的标签。\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_tensor, labels_tensor):\n",
    "        \"\"\"\n",
    "        初始化数据集\n",
    "        :param data: 输入数据，通常是一个列表或数组\n",
    "        :param labels: 对应的标签，通常是一个列表或数组\n",
    "        \"\"\"\n",
    "        self.data_tensor = data_tensor\n",
    "        self.labels_tensor = labels_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集的大小\n",
    "        \"\"\"\n",
    "        return self.data_tensor.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        根据索引获取一个样本\n",
    "        \"\"\"\n",
    "        return self.data_tensor[idx], self.labels_tensor[idx]\n",
    "    \n",
    "# 示例数据\n",
    "data_tensor = torch.randn(10, 3)\n",
    "labels_tensor = torch.randint(2, (10,)) # 二分类标签\n",
    "\n",
    "\n",
    "my_dataset = MyDataset(data_tensor, labels_tensor)\n",
    "\n",
    "print(\"数据集大小:\", len(my_dataset))\n",
    "for i in range(len(my_dataset)):\n",
    "    data, label = my_dataset[i]\n",
    "    print(f\"样本 {i}: 数据 = {data}, 标签 = {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62280025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用 iter 和 next 获取的第一个批次数据: [tensor([[-2.1477,  0.5268,  0.3675],\n",
      "        [ 1.0030,  1.0919, -0.8640]]), tensor([1, 1])]\n",
      "使用 iter 和 next 获取的第二个批次数据: [tensor([[-0.5267, -1.0533, -0.3102],\n",
      "        [-1.0900,  0.1568, -0.4889]]), tensor([0, 0])]\n"
     ]
    }
   ],
   "source": [
    "# DataLoader 类\n",
    "# PyTorch 中的 DataLoader 类用于将 Dataset 封装成一个可迭代的数据加载器\n",
    "# 它提供了批量加载数据、打乱数据顺序以及多线程数据加载等功能\n",
    "# DataLoader 的常用参数包括：\n",
    "# dataset：要加载的数据集，通常是一个 Dataset 对象；\n",
    "# batch_size：每个批次加载的数据样本数量，默认为 1；\n",
    "# shuffle：是否打乱数据顺序，默认为 False；\n",
    "# num_workers：用于数据加载的子进程数量，默认为 0（即不使用多线程）；\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tensor_dataloader = DataLoader(my_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "# for batch in tensor_dataloader:\n",
    "#     data, labels = batch\n",
    "#     print(\"批次数据:\", data)\n",
    "#     print(\"批次标签:\", labels)\n",
    "\n",
    "# iter 和 next 函数\n",
    "# 在 Python 中，iter() 函数用于返回一个可迭代对象的迭代器\n",
    "# next() 函数用于从迭代器中获取下一个元素\n",
    "data_iterator = iter(tensor_dataloader)\n",
    "first_batch = next(data_iterator)\n",
    "print(\"使用 iter 和 next 获取的第一个批次数据:\", first_batch)\n",
    "\n",
    "# 下一个\n",
    "second_batch = next(data_iterator)\n",
    "print(\"使用 iter 和 next 获取的第二个批次数据:\", second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db24b28",
   "metadata": {},
   "source": [
    "# Torchvision\n",
    "`torchvision` 是 PyTorch 的一个子库，专门用于计算机视觉任务。它提供了常用的数据集、预训练模型和图像变换工具，极大地方便了图像处理和深度学习模型的开发。以下是 `torchvision` 的主要组件：\n",
    "\n",
    "## 数据集（Datasets）\n",
    "`torchvision.datasets` 模块包含了许多常用的计算机视觉数据集，如 CIFAR-10、MNIST、ImageNet 等。使用这些数据集时，可以直接通过 `torchvision.datasets` 提供的类来加载数据，并进行必要的预处理。\n",
    "\n",
    "The [link](https://pytorch.org/vision/stable/datasets.html) for more details of all supported datasets.\n",
    "\n",
    "torchvision.datasets这个包本身并不包含数据集的文件本身，它的工作方式是先从网络上把数据集下载到用户指定目录，然后再用它的加载器把数据集加载到内存中。\n",
    "\n",
    "最后，把这个加载后的数据集作为对象返回给用户。\n",
    "\n",
    "### MNIST 数据集\n",
    "MNIST 数据集是 NIST 数据集的一个子集\n",
    "\n",
    "![MNIST 数据集示例](mdfiles/image1.png)\n",
    "\n",
    "如何使用 Torchvision 来读取 MNIST 数据集\n",
    "\n",
    "1. train：是布尔类型，表示是否加载训练集数据。如果为 True，则只加载训练数据。如果为 False，则只加载测试数据集。这里需要注意，并不是所有的数据集都做了训练集和测试集的划分，这个参数并不一定是有效参数，具体需要参考官方接口说明文档\n",
    "2. transform：用于对图像进行预处理操作，例如数据增强、归一化、旋转或缩放等。\n",
    "3. target_transform：用于对标签进行预处理操作，例如将标签转换为 one-hot 编码等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2cb08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "mnist_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=None, target_transform=None, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1d69217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAklEQVR4AWIY1IBZSEiormO91LL/3+tBDmUBESAsx2ZlIxAMYj2ZFPj54kEQixFEMDAwGO7lh7L+JX1lePb+JpQHBkK3/4LAsW3fP4L5qETAnOy/f89yM2jPQhWHAD7GWX+jIEwYyQRjMHz6/5EhBcGFi0MB976/blAmFkr548MFOTD3Y8gHfvj7t1wSQxgKdHf9/TtNGsrBoARi//zdjSEKBz///nSAcuBhC+HrhZiyMFw7BOGgkoCpT3n69+/fX9tQRcE8iaK7oOA96QfmoRDiTldBUscCMQNJaDU4Vg4HcKLoAHHM1zwC6frSyg3iITDYtYGBDAzXN//t+YAQpyULAEUXXoDz1Y8qAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image label is: 5\n"
     ]
    }
   ],
   "source": [
    "# print the list of the dataset\n",
    "print(mnist_dataset)\n",
    "mnist_dataset_list = list(mnist_dataset)\n",
    "display(mnist_dataset_list[0][0])\n",
    "print(\"Image label is:\", mnist_dataset_list[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f8d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 PyTorch 中，我们要定义一个数据集，应该继承哪一个类呢？\n",
    "# 答案是 Dataset 类"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rad-dino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
