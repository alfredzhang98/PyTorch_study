{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68ce55d",
   "metadata": {},
   "source": [
    "# 张量的数据结构\n",
    "Tensor 是深度学习框架中极为基础的概念，也是 PyTroch、TensorFlow 中最重要的知识点之一，它是一种数据的存储和处理结构。\n",
    "\n",
    "标量，也称 Scalar，是一个只有大小，没有方向的量，比如 1.8、e、10 等。\n",
    "\n",
    "向量，也称 Vector，是一个有大小也有方向的量，比如 (1,2,3,4) 等。\n",
    "\n",
    "矩阵，也称 Matrix，是多个向量合并在一起得到的量，比如[(1,2,3),(4,5,6)]等。\n",
    "\n",
    "\n",
    "![mdfiles/image2.png](mdfiles/image2.png)\n",
    "\n",
    "Rank（秩）来表示这种“维度”，比如标量，就是 Rank 为 0 阶的 Tensor；向量就是 Rank 为 1 阶的 Tensor；矩阵就是 Rank 为 2 阶的 Tensor。也有 Rank 大于 2 的 Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb1c6c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5.]], device='cuda:0')\n",
      "tensor([1, 2, 3, 4, 5])\n",
      "zeros_tensor: tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "ones_tensor: tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "eye_tensor: tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "arange_tensor: tensor([0., 2., 4., 6., 8.])\n",
      "linspace_tensor: tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
      "rand_tensor: tensor([[0.9110, 0.3321, 0.9602],\n",
      "        [0.7950, 0.6236, 0.7947],\n",
      "        [0.0589, 0.4025, 0.0117]])\n",
      "randn_tensor: tensor([[-1.3588, -2.4594,  0.3198, -0.0436],\n",
      "        [-2.0158,  0.0813,  0.0378, -0.2368]])\n",
      "randperm_tensor: tensor([9, 3, 7, 4, 8, 0, 6, 5, 1, 2])\n",
      "normal_tensor: tensor([[ 1.6344, -1.2577,  0.2292],\n",
      "        [ 0.2665, -0.8695,  1.3954],\n",
      "        [-0.4596, -0.8160, -1.6917]])\n",
      "randint_tensor: tensor([[8, 2, 2, 2],\n",
      "        [4, 7, 7, 1],\n",
      "        [2, 0, 7, 5],\n",
      "        [2, 8, 4, 7]])\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data = [1, 2, 3, 4, 5]\n",
    "# data could be a list, tuple, numpy ndarray, scalar\n",
    "# list: [1, 2, 3, 4, 5]\n",
    "# tuple: (1, 2, 3, 4, 5)\n",
    "# numpy ndarray: np.array([1, 2, 3, 4, 5])\n",
    "# scalar: 5 (scalar is converted to a 0-dim tensor)\n",
    "# requires_grad is used for 自动求导机制 autograd 的开关，用来控制这个张量是否参与梯度计算\n",
    "torch_tensor = torch.tensor([data],dtype=torch.float32,device='cuda:0',requires_grad=False)\n",
    "print(torch_tensor)\n",
    "\n",
    "# create from numpy\n",
    "torch_tensor_from_numpy = torch.from_numpy(np.array(data))\n",
    "print(torch_tensor_from_numpy)\n",
    "\n",
    "# torch.zeros ：创建一个指定形状的全零张量\n",
    "zeros_tensor = torch.zeros(size=(3, 4), dtype=torch.float32)\n",
    "# torch.ones ：创建一个指定形状的全一张量\n",
    "ones_tensor = torch.ones(size=(2, 5), dtype=torch.float32)\n",
    "# torch.eyes ：创建一个单位矩阵张量\n",
    "eye_tensor = torch.eye(n=4, m=4, dtype=torch.float32)\n",
    "# torch.arange ：创建一个一维张量，包含指定范围内的等差数列\n",
    "arange_tensor = torch.arange(start=0, end=10, step=2, dtype=torch.float32)\n",
    "# torch.linspace ：创建一个一维张量，包含指定范围内的等间隔数列\n",
    "linspace_tensor = torch.linspace(start=0, end=1, steps=5, dtype=torch.float32)\n",
    "# torch.rand ：创建一个指定形状的张量，元素服从均匀分布\n",
    "rand_tensor = torch.rand(size=(3, 3), dtype=torch.float32)\n",
    "# torch.randn ：创建一个指定形状的张量，元素服从标准正态分布\n",
    "randn_tensor = torch.randn(size=(2, 4), dtype=torch.float32)\n",
    "# torch.randperm ：创建一个一维张量，包含指定范围内的随机排列整数\n",
    "randperm_tensor = torch.randperm(n=10, dtype=torch.int64)\n",
    "# torch.normal ：创建一个指定形状的张量，元素服从正态分布\n",
    "normal_tensor = torch.normal(mean=0.0, std=1.0, size=(3, 3), dtype=torch.float32)\n",
    "# torch.randint ：创建一个指定范围内的随机整数张量\n",
    "randint_tensor = torch.randint(low=0, high=10, size=(4, 4), dtype=torch.int64)\n",
    "\n",
    "print(f\"zeros_tensor: {zeros_tensor}\")\n",
    "print(f\"ones_tensor: {ones_tensor}\")\n",
    "print(f\"eye_tensor: {eye_tensor}\")\n",
    "print(f\"arange_tensor: {arange_tensor}\")\n",
    "print(f\"linspace_tensor: {linspace_tensor}\")\n",
    "print(f\"rand_tensor: {rand_tensor}\")\n",
    "print(f\"randn_tensor: {randn_tensor}\")\n",
    "print(f\"randperm_tensor: {randperm_tensor}\")\n",
    "print(f\"normal_tensor: {normal_tensor}\")\n",
    "print(f\"randint_tensor: {randint_tensor}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36848077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from int: 5\n",
      "Type: <class 'torch.Tensor'>\n",
      "Tensor value: 5\n",
      "Type: <class 'int'>\n",
      "Tensor from list: tensor([1, 2, 3, 4, 5])\n",
      "List from tensor: [1, 2, 3, 4, 5]\n",
      "Type of tensor_from_list: <class 'torch.Tensor'>\n",
      "Type of list_from_tensor: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 转换\n",
    "\n",
    "# INT and Tensor conversion\n",
    "int_value = 5\n",
    "tensor_from_int = torch.tensor(int_value)\n",
    "print(f\"Tensor from int: {tensor_from_int}\")\n",
    "print(f\"Type: {type(tensor_from_int)}\")\n",
    "\n",
    "# item\n",
    "tensor_value = tensor_from_int.item()\n",
    "print(f\"Tensor value: {tensor_value}\")\n",
    "print(f\"Type: {type(tensor_value)}\")\n",
    "\n",
    "# list to tensor and back\n",
    "list_value = [1, 2, 3, 4, 5]\n",
    "tensor_from_list = torch.tensor(list_value)\n",
    "list_from_tensor = tensor_from_list.numpy().tolist()\n",
    "print(f\"Tensor from list: {tensor_from_list}\")\n",
    "print(f\"List from tensor: {list_from_tensor}\")\n",
    "print(f\"Type of tensor_from_list: {type(tensor_from_list)}\")\n",
    "print(f\"Type of list_from_tensor: {type(list_from_tensor)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0614b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Tensor: tensor([1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# CPU 与 GPU 的 Tensor\n",
    "cpu_tensor = torch.tensor([1, 2, 3], device='cpu')\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tensor = cpu_tensor.to('cuda:0')\n",
    "    print(f\"GPU Tensor: {gpu_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cee30a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor a: tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "Shape of a: torch.Size([2, 3, 5])\n",
      "Dimensions of a: 3\n",
      "Size of a: torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 的形式、形状\n",
    "a=torch.zeros(2, 3, 5)\n",
    "print(f\"Tensor a: {a}\")\n",
    "print(f\"Shape of a: {a.shape}\")\n",
    "print(f\"Dimensions of a: {a.ndim}\")\n",
    "print(f\"Size of a: {a.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6171d9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in a: 30\n"
     ]
    }
   ],
   "source": [
    "# numel()：返回张量中元素的总数\n",
    "a=torch.zeros(2, 3, 5)\n",
    "print(f\"Number of elements in a: {a.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a020f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4])\n",
      "torch.Size([3, 2, 4])\n",
      "True\n",
      "False\n",
      "True\n",
      "torch.Size([6, 4])\n",
      "torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "# 矩阵转秩 (维度转换）\n",
    "a = torch.randn(2, 3, 4)\n",
    "b = a.permute(1, 0, 2)  # 交换维度 具体来说 交换了第0维和第1维\n",
    "print(b.shape)  # 输出: torch.Size([3, 2, 4])\n",
    "\n",
    "# transpose()：交换指定的两个维度\n",
    "c = a.transpose(0, 1)  # 交换第0维和第1维\n",
    "print(c.shape)  # 输出: torch.Size([3, 2, 4])\n",
    "\n",
    "# 经过了 transpose 或者 permute 处理之后的数据，变得不再连续了\n",
    "# 具体来说，如果一个张量在内存中不是按行优先（row-major）顺序存储的，那么它就是不连续的\n",
    "# contiguous()：将不连续的张量转换为连续的张量\n",
    "print(a.is_contiguous())  # 输出: True\n",
    "print(b.is_contiguous())  # 输出: False\n",
    "d = b.contiguous()\n",
    "print(d.is_contiguous())  # 输出: True\n",
    "\n",
    "\n",
    "# view 不能处理内存不连续 Tensor 的结构。\n",
    "# 如果对一个不连续的 Tensor 使用 view 方法，会报错。\n",
    "# 这时候需要先调用 contiguous 方法，将其转换为连续的 Tensor，然后再使用 view 方法。\n",
    "e = d.view(6, 4)\n",
    "print(e.shape)  # 输出: torch.Size([6, 4])\n",
    "# 如果直接对 b 使用 view 方法，会报错\n",
    "# f = b.view(6, 4)  # 会报错，因为 b 是不连续的 Tensor d 已经是连续的 Tensor 了，可以使用 view 方法\n",
    "\n",
    "# view 不行 reshape 可以\n",
    "f = b.reshape(6, 4)\n",
    "print(f.shape)  # 输出: torch.Size([6, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4c963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([2, 1, 3, 1, 4])\n",
      "Squeezed shape: torch.Size([2, 1, 3, 1, 4])\n",
      "Unsqueezed shape: torch.Size([2, 1, 1, 3, 1, 4])\n",
      "Unsqueezed2 shape: torch.Size([2, 1, 1, 1, 3, 1, 4])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# Really important\n",
    "# seqeeze and unsqueeze to add or remove dimensions\n",
    "x = torch.randn(2, 1, 3, 1, 4)\n",
    "print(f\"Original shape: {x.shape}\")  # 输出: torch.Size([2, 1, 3, 1, 4])\n",
    "x_squeezed = x.squeeze()\n",
    "# 输入的只能是维度为1的维度，否则不会被移除，例如1和3维度 其他维度不是1就不会被移除\n",
    "print(f\"Squeezed shape: {x_squeezed.shape}\")  # 输出: torch.Size([2, 3, 4]) why?\n",
    "# 因为 squeeze() 会移除所有维度为 1 的维度\n",
    "x_unsqueezed = x_squeezed.unsqueeze(1)\n",
    "print(f\"Unsqueezed shape: {x_unsqueezed.shape}\")  # 输出: torch.Size([2, 1, 3, 4]) why?\n",
    "x_unsqueezed2 = x_unsqueezed.unsqueeze(3)\n",
    "print(f\"Unsqueezed2 shape: {x_unsqueezed2.shape}\")  # 输出: torch.Size([2, 1, 3, 1, 4]) why?\n",
    "# 因为 unsqueeze(1) 会在第 1 and 3 个维度位置添加一个维度，大小为 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Tensor() 和 torch.tensor() 区别\n",
    "# torch.Tensor() 是一个类的构造函数，用于创建一个新的张量对象。它可以接受多种类型的输入参数，如列表、元组、NumPy 数组等。\n",
    "# torch.tensor() 是一个函数，用于将现有的数据转换为张量对象。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rad-dino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
