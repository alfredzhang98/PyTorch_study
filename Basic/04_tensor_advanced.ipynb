{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb74775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[1., 1., 1., 2., 2., 2.],\n",
      "        [1., 1., 1., 2., 2., 2.],\n",
      "        [1., 1., 1., 2., 2., 2.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 的连接\n",
    "import torch\n",
    "a = torch.ones(3, 3)\n",
    "b = 2 * torch.ones(3, 3)\n",
    "print(a)\n",
    "print(b)\n",
    "c = torch.cat((a, b), dim=1)\n",
    "print(c)\n",
    "\n",
    "c = torch.cat((a, b), dim=0)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e12b5304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[2., 2., 2.],\n",
      "         [2., 2., 2.],\n",
      "         [2., 2., 2.]]])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [2., 2., 2.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [2., 2., 2.]]])\n"
     ]
    }
   ],
   "source": [
    "# 增加维度 stack\n",
    "c = torch.stack((a, b), dim=0)\n",
    "print(c)\n",
    "\n",
    "c = torch.stack((a, b), dim=1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db67cdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 shape: torch.Size([4, 64, 64])\n",
      "Chunk 1 shape: torch.Size([4, 64, 64])\n",
      "Chunk 2 shape: torch.Size([4, 64, 64])\n",
      "Chunk 3 shape: torch.Size([4, 64, 64])\n",
      "Chunk 4 shape: torch.Size([4, 64, 64])\n",
      "Chunk 5 shape: torch.Size([4, 64, 64])\n",
      "Chunk 6 shape: torch.Size([4, 64, 64])\n",
      "Chunk 7 shape: torch.Size([4, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 切分 chunk\n",
    "\n",
    "# 32 channels\n",
    "input = torch.randn(32, 64, 64)\n",
    "# split into 8 chunks along channel dimension\n",
    "chunks = torch.chunk(input, 8, dim=0)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i} shape: {chunk.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5822b840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0: tensor([1, 2, 3, 4])\n",
      "Chunk 1: tensor([5, 6, 7, 8])\n",
      "Chunk 2: tensor([ 9, 10])\n"
     ]
    }
   ],
   "source": [
    "A=torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "# 不等量切分\n",
    "B = torch.chunk(A, 3, 0)\n",
    "for i, b in enumerate(B):\n",
    "    print(f\"Chunk {i}: {b}\")\n",
    "\n",
    "# 长度分别是 4，4，2 位。这是怎么分的呢，不应该是 3，3，4 这样更为平均的方式么？\n",
    "# chunk 函数是先做除法，然后再向上取整得到每组的数量（注意是向上取整）\n",
    "\n",
    "# 那如果 chunk 参数大于 Tensor 可以切分的长度，就会把被切分的 Tensor 只能分成若干个长度为 1 的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9280491f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0: tensor([[0.5663, 0.6546, 0.4672, 0.8208],\n",
      "        [0.9446, 0.2627, 0.3186, 0.3258]])\n",
      "Split 1: tensor([[0.6373, 0.4146, 0.5292, 0.9575],\n",
      "        [0.4755, 0.1363, 0.9701, 0.1527]])\n",
      "Split 0: tensor([[0.8965, 0.9684, 0.7533, 0.8419],\n",
      "        [0.8409, 0.1131, 0.0438, 0.3762]])\n",
      "Split 1: tensor([[0.3917, 0.3818, 0.5565, 0.8991],\n",
      "        [0.1206, 0.9700, 0.0465, 0.3075]])\n",
      "Split 2: tensor([[0.1655, 0.3694, 0.8687, 0.8399]])\n"
     ]
    }
   ],
   "source": [
    "# chunk 函数，是按照“切分成确定的份数”来进行切分的，那如果想按照“每份按照确定的大小”来进行切分\n",
    "# 可以使用 torch.split 函数\n",
    "\n",
    "A=torch.rand(4,4)\n",
    "# split size_or_sections 可以是一个整数，表示每一份的大小\n",
    "B = torch.split(A, 2, dim=0)\n",
    "for i, b in enumerate(B):\n",
    "    print(f\"Split {i}: {b}\")\n",
    "\n",
    "\n",
    "A=torch.rand(5,4)\n",
    "# split_size_or_sections 可以是一个列表，表示每一份的大小\n",
    "B=torch.split(A,(2,2,1),0)\n",
    "for i, b in enumerate(B):\n",
    "    print(f\"Split {i}: {b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f251304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbind 0: tensor([[-1.2208, -0.2413,  1.6901, -0.5783, -1.6049],\n",
      "        [ 0.8374,  0.9689, -0.0543, -0.3896, -0.0918],\n",
      "        [ 0.6151, -0.3588, -1.9207,  2.6521, -0.8539]])\n",
      "Unbind 1: tensor([[-0.4769, -0.7594, -0.5618,  0.4039,  0.4695],\n",
      "        [-2.1413, -1.5147,  0.1714,  0.7763,  0.9834],\n",
      "        [-0.4921,  0.3430, -0.8709, -0.5011,  1.5466]])\n",
      "Unbind 2: tensor([[-1.1893, -1.4522, -0.8917,  1.0523,  1.0498],\n",
      "        [-2.2550, -2.0617,  1.4712,  0.1001,  0.2586],\n",
      "        [ 1.0543, -0.4837,  1.2428, -0.1238, -0.2266]])\n",
      "Unbind 3: tensor([[ 1.6378,  0.8954,  0.6025, -0.4242, -0.2850],\n",
      "        [ 1.0454,  0.4556,  1.1422, -0.1685,  0.0769],\n",
      "        [ 1.0211, -0.8556, -0.8372, -0.7319,  0.6541]])\n"
     ]
    }
   ],
   "source": [
    "# unbind 函数：沿指定维度移除张量的一个维度，并返回一个元组，包含所有切片后的张量\n",
    "A = torch.randn(3, 4, 5)\n",
    "B = torch.unbind(A, dim=1)\n",
    "# if dim is 1 means unbind along the second dimension\n",
    "for i, b in enumerate(B):\n",
    "    print(f\"Unbind {i}: {b}\")\n",
    "\n",
    "# unbind 是一种降维切分的方式，相当于删除一个维度之后的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4de17f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor([2, 5, 8])\n",
      "tensor([4, 5, 6])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([[ 4,  5,  6,  7],\n",
      "        [12, 13, 14, 15]])\n",
      "tensor([[ 0,  3],\n",
      "        [ 4,  7],\n",
      "        [ 8, 11],\n",
      "        [12, 15]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor 的索引操作\n",
    "a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(a[0, 0])  # 输出: tensor(1)\n",
    "print(a[:, 1])  # 输出: tensor([2, 5, 8])\n",
    "print(a[1, :])  # 输出: tensor([4, 5, 6])\n",
    "\n",
    "# index_select\n",
    "A=torch.arange(0,16).view(4,4)\n",
    "print(A)\n",
    "B=torch.index_select(A,0,torch.tensor([1,3]))\n",
    "C=torch.index_select(A,1,torch.tensor([0,3]))\n",
    "print(B)\n",
    "print(C)\n",
    "\n",
    "# 从第 0 维选择第 1（行）和 3（行）的数据，并得到了最终的 Tensor B，其大小为 2x4。\n",
    "# Tensor A 中选择第 0（列）和 3（列）的数据，得到了最终的 Tensor C，其大小为 4x2。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26a0dfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4882,  1.0881,  0.1695,  0.8314],\n",
      "        [ 0.8505,  0.0342, -0.7567,  0.0437],\n",
      "        [-0.0247,  0.3069,  1.8622,  0.6370],\n",
      "        [ 0.2714,  0.0234, -0.0063, -1.7876]])\n",
      "tensor([1.0881, 0.8314, 0.8505, 0.3069, 1.8622, 0.6370])\n"
     ]
    }
   ],
   "source": [
    "# masked_select\n",
    "# 通过一些判断条件来进行选择，比如提取深度学习网络中某一层中数值大于 0 的参数。\n",
    "A = torch.randn(4, 4)\n",
    "B = torch.masked_select(A, A > 0.3,out=None)\n",
    "print(A)    \n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d75ca",
   "metadata": {},
   "source": [
    "# 常用汇总\n",
    "\n",
    "![mdfiles/image3.png](mdfiles/image3.png)\n",
    "\n",
    "\n",
    "index_select 返回的结果和输入是一个维度，而masked_select返回一维输出\n",
    "stack和cat的一个不同点在于，stack会升维，而cat不会。\n",
    "split获取的是原输入的视图，也就是对split的结果的操作会影响原来的数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8ad6a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5, 7],\n",
      "        [3, 9, 8],\n",
      "        [2, 3, 4]])\n",
      "tensor([4, 3, 9, 4])\n"
     ]
    }
   ],
   "source": [
    "A=torch.tensor([[4,5,7], [3,9,8],[2,3,4]])\n",
    "\n",
    "print(A)\n",
    "\n",
    "\n",
    "mask = torch.tensor([[1,0,0], [1,1,0],[0,0,1]], dtype=torch.bool)\n",
    "selected = torch.masked_select(A, mask>0)\n",
    "print(selected)  # 输出: tensor([4, 9, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rad-dino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
